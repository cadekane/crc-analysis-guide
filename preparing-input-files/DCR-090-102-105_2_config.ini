
[RUNTIME]
; these usually change with each batch of data
groupname = DCR-090-102-105_2
; this is usually a reference to the accession or source of the data
input_file = /home/ckane/DAS/dcr_1/csv_input/DCR-090-102-105_2.csv
ref_version = b37
; option of b37 or hg38
raw_file_dir = /home/ckane/DAS/dcr_1
; parent directory where the BAM, PON, and MAF files are expected to be
;; note: the pipeline does not move these files here automatically, the files must be moved manually
send_email_for_all = False
; sends email for each workflow that completes, this can get overwhelming if processing a large batch of data. By default, an email with always be sent when the last workflow inputted has completed
;; value is either True or False
interval_file = /home/imibrahim/refs/b37/hg19-wgs_calling_regions.v1.interval_list
;; path to the interval file. Leave empty to use the default interval files for b37 and hg38 (WGS)
;; this specified path is for WGS! Check if the pon and mutect jsons have this as the path.

[USERCONFIG]
; user specific settings: you would usually only change this the first time you get this conf
email = cadekane@hawaii.edu
base_output_dir = /home/ckane/DAS/dcr_1/cromwell_input
; location where JSONs generated by this script will be output
;; the script will save all JSONs in a subdirectory of the same groupname e.g. /base/output/dir/groupname

[RAWFILEDIRS]
; directory structure where the raw files are expected to be on the server: this would also usually only be set once, unless you change directory structures for each run
n_dir = bam/b37-n/DCR-090-102-105_2
; e.g. /raw/file/dir/bam/b37-n
t_dir = bam/b37-t/DCR-090-102-105_2
pon_dir = pon/DCR-090-102-105_2
; e.g. /raw/file/dir/pon/

[SERVERCONFIG]
; server specific run: these would rarely change
gatk_docker = arashi-gatk-426
; this refers to the container (singularity/docker) used for the pipeline. These containers are located at /home/imibrahim/SIFs
ref_dir = /home/imibrahim/refs
; this is the location of the reference files on ARASHI. Don't change unless intending to use the pipeline with own set of references not defined here
